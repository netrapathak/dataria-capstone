{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_Match.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNcix3PQA3LqZAcY27QmHuv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/netrapathak/dataria-capstone/blob/master/NN_Match.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGrduAunqDda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from cleanco import cleanco\n",
        "import re\n",
        "import unicodedata\n",
        "!pip install ftfy\n",
        "from ftfy import fix_text\n",
        "import sys\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse import csr_matrix\n",
        "!pip install sparse_dot_topn \n",
        "import sparse_dot_topn.sparse_dot_topn as ct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpJ0pLksqF9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evrqYrjnqGHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Import dataframes here. \n",
        "#Pitchbook data\n",
        "pitch = pd.read_csv('Pitchbook.csv', dtype='unicode')\n",
        "#USPTO data\n",
        "uspto = pd.read_csv('uspto.csv', dtype='unicode')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGQ-Un8UqPbZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ngrams(string, n=3):\n",
        "    string = fix_text(string) \n",
        "    string = string.encode(\"ascii\", errors=\"ignore\").decode() \n",
        "    string = string.lower() \n",
        "    chars_to_remove = [\")\",\"(\",\".\",\"|\",\"[\",\"]\",\"{\",\"}\",\"'\"]\n",
        "    rx = '[' + re.escape(''.join(chars_to_remove)) + ']'\n",
        "    string = re.sub(rx, '', string) \n",
        "    string = string.replace('&', 'and')\n",
        "    string = string.replace(',', ' ')\n",
        "    string = string.replace('-', ' ')\n",
        "    string = string.title() \n",
        "    string = re.sub(' +',' ',string).strip()\n",
        "    string = ' '+ string +' ' \n",
        "    string = re.sub(r'[,-./]|\\sBD',r'', string)\n",
        "    ngrams = zip(*[string[i:] for i in range(n)])\n",
        "    return [''.join(ngram) for ngram in ngrams]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRBd6XmyqsP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This is the record linkage approach. Use this approach. \n",
        "#Company name column from pitchbook.\n",
        "org_name_clean = pitch['Company Legal Name'].unique()\n",
        "vectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams, lowercase=False)\n",
        "tfidf = vectorizer.fit_transform(org_name_clean.astype('U'))\n",
        "print('Vecorizing completed...')\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "nbrs = NearestNeighbors(n_neighbors=1, n_jobs=-1).fit(tfidf)\n",
        "#Company name column from uspto.\n",
        "org_column = uspto['organization'] #column to match against in the messy data\n",
        "\n",
        "unique_org = set(org_column.astype('U')) \n",
        "\n",
        "def getNearestN(query):\n",
        "    queryTFIDF_ = vectorizer.transform(query)\n",
        "    distances, indices = nbrs.kneighbors(queryTFIDF_)\n",
        "    return distances, indices\n",
        "\n",
        "import time\n",
        "t1 = time.time()\n",
        "print('getting nearest n...')\n",
        "distances, indices = getNearestN(unique_org)\n",
        "t = time.time()-t1\n",
        "print(\"COMPLETED IN:\", t)\n",
        "unique_org = list(unique_org) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaNpFrRxq0bL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matches = []\n",
        "for i,j in enumerate(indices):\n",
        "    temp = [round(distances[i][0],2), pitch.values[j][0][1],unique_org[i]]\n",
        "    matches.append(temp)\n",
        "print('Building data frame...')  \n",
        "matches = pd.DataFrame(matches, columns=['Match confidence (lower is better)','Matched name','Original name'])\n",
        "print('Done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU2kQhKAq4Fj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "match = matches.sort_values(by=['Match confidence (lower is better)'])\n",
        "match_1 = match[match['Match confidence (lower is better)'] < 0.79]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_eluSo_q_ww",
        "colab_type": "text"
      },
      "source": [
        "Use match_1['Matched Name'] to join with pitchbook dataset.\n",
        "\n"
      ]
    }
  ]
}